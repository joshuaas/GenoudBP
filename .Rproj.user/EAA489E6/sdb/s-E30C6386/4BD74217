{
    "contents" : "\n  sigm=function(z){\n      1  / ( 1 + exp ( - z ) )\n    }\n########################################\n#'@description genoudBP\n#'@description this function is used to build an ANN model based on genoudBP algrithm and returning a model of\n#'a S3 class genoudBP\n#'@param trian_x : the training input used to build the returning model\n#'@param train_y : the training output used to build the returning model\n#'@param multi   : see definition of dataSeparation\n#'@param hid_num : number of hidden layer nodes\n#'@param lambda   : coefficient for tuning regularization\n#'@param maxiter : maximum number of Genoud iteration\n#'@param cluster : the cluster parameter for Genoud\n#'@param center  : see dataSeparation\n#'@param scale   : see dataSeparation\n#'@param n_out   : see dataSeparation\n#'@param BFGS    : a logical value to indicate whether to use BFGS algorithm during genoud\n#'@return this function returns a ANN model with S3 class GenoudBP we have implemented two general functons\n#'i.e. predict & performaceEval for that class\n#'@return n_f    : the number of input dimensions\n#'@return w1_fit : W^(1) i.e. the weight matrix between input layer and hidden layer\n#'@return w2_fit : W^(2) i.e. the weight matrix between hidden layer and output layer \n#'@return op     : the genoudBP result\n\ngenoudBp <- function(train_x,train_y,multi,hid_num,lambda=0.2,maxiter=100,cluster = F,center,scale,n_out,BFGS = BFGS,...){\n \n\n    # sigmoid function ---'----------------------------------------------------\n    #'@description the sigmoid is used as the transformation function through out the whole network\n    #'\n    sigm=function(z){\n      1  / ( 1 + exp ( - z ) );\n    }\n    \n    #'@description the loss function\n    fn <- function(x){\n          \n          w1_fun=matrix(x[1:(hid_num*n_f)],nrow = hid_num,byrow = T)\n          w2_fun= matrix(x[(hid_num*n_f+1):(hid_num*n_f+ n_out *(hid_num+1) )],nrow=n_out,byrow=T)  #needa change\n          if(multi){\n             h  <- matrix(0,nrow =train_num,ncol = n_out)\n             multi <- T\n          }else{\n            h=rep(0,train_num)\n            \n          }\n          \n          a2 <- rep(0,hid_num)\n          a1 <- rep(0,n_f)\n          a3  <- rep(0,n_out)\n          lapply(1:train_num,function(i){\n            a1 <<- train_x[i,]\n            a2 <<- sigm(w1_fun%*%a1)\n            a2 <<- c(1,a2)\n            a3 <<- sigm(w2_fun%*%a2)\n            if(multi){\n               h[i,] <<- a3\n            }else{\n              h[i] <<- a3\n              \n            }\n          }\n          )\n          \n          if (multi){\n            h  <- as.matrix(h)\n          }else{\n            h <<- as.vector(h)            \n          }\n          \n          if( multi ){\n              J <- -sum(train_y* log(h) + (1-train_y) *log(1-h),c(1,2)) /  (2 *train_num)    \n            \n          }else{\n           \n            J <- - ( train_y %*% log(h) + (1-train_y) %*% log(1 - h))  / (2 * train_num )\n            \n          }\n          \n          reg= lambda * ( sum( w1_fun[,-1]^2 , c(1,2) ) + sum( w2_fun[,-1]^2 , c(1,2) ) )  / ( 2 * train_num )\n          J = J + reg\n          J\n          \n          \n        }\n\n    #'@description the gradient function\n    grad <- function(x){\n          \n          w1_fun <- matrix(x[1:(hid_num*n_f)],nrow=hid_num,byrow=T)\n          w2_fun= matrix(x[(hid_num*n_f+1):(hid_num*n_f+ n_out *(hid_num+1) )],nrow=n_out,byrow=T)  #needa change\n          \n          Delta1 <- matrix(0,hid_num,n_f)\n          Delta2 <- matrix(0,n_out,hid_num+1)   #needa change\n          delta3 <- rep(0,n_out)\n          delta2 <- rep(0,hid_num+1)\n          #         D2=Delta2;\n          #         D1=Delta1;   \n          a1 <- as.numeric(rep(0,n_f))\n          a2 <- as.numeric(rep(0,hid_num))\n          \n          lapply(1:train_num,function(x){\n            a2 <<- c(1,sigm(w1_fun %*% train_x[x,])) \n            if(multi){\n              delta3 <<-  sigm(\n                w2_fun %*% a2    \n              )  - train_y[x,]  \n            }else{\n              delta3 <<-  sigm(\n                w2_fun %*% a2    \n              )  - train_y[x]  \n            }\n            \n                  \n            delta2 <<- t(w2_fun)%*%delta3*a2*(1-a2)  \n            Delta2 <<- Delta2+delta3%*%t(a2)\n            Delta1 <<- Delta1+(delta2%*%t(train_x[x,]))[-1,]\n            \n          })\n                    \n              \n          \n          \n          Delta2[,-1] <- Delta2[,-1]/(train_num)+lambda*w2_fun[,-1]\n          Delta1[,-1] <- Delta1[,-1]/(train_num)+lambda*w1_fun[,-1]\n          Delta2[,1]  <- Delta2[,1]/(train_num)\n          Delta1[,1]  <- Delta1[,1]/(train_num)\n          \n          \n          c(as.vector(t(Delta1)),as.vector(t(Delta2)))        \n          \n          \n        }\n    \n\n    \n        n_f   <- ncol(train_x)\n        train_num  <- nrow(train_x)\n###########generate sample###############        \n             \n        nvar=hid_num*n_f+(hid_num+1) * n_out;\n         \n# initialize --------------------------------------------------------------\n\n        \n\n        w1=runif(hid_num * (n_f),-1,1)\n        w2=runif(n_out * (hid_num+1),-1,1)  #need change\n        inpar=c(w1,w2);\n\n\n\n# optimize ----------------------------------------------------------------\n        ##change for multiclass classification\n        domains=rep(c(-1,1),nvar);\n        domains=matrix(domains,byrow=T,nrow=nvar);\n\n        op=genoud(fn=fn,gr=grad,nvars=nvar,starting.values=inpar,print.level=0,\n                  Domains=domains,boundary.enforcement=1,max.generations=maxiter,...,\n                  debug=T,gradient.check=F,pop.size=40,cluster = cluster,P9=0,BFGS =BFGS);\n\n        w1_fit=matrix(op$par[1:(hid_num*(n_f))],byrow=T,nrow=hid_num);\n        w2_fit=matrix(op$par[(hid_num*n_f+1):(hid_num*n_f+ n_out *(hid_num+1) )],\n                      nrow=n_out,byrow=T);\n        \n\n \n\n    # return value ------------------------------------------------------------\n    structure(list(n_f=n_f,hid_num=hid_num,n_out = n_out,w1_fit=w1_fit,w2_fit=w2_fit,likelihood=op$value,\n         op = op,multi =multi,center =center,scale =scale),class =\"GenoudBP\")\n  \n}",
    "created" : 1420194861946.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2632092345",
    "id" : "4BD74217",
    "lastKnownWriteTime" : 1420195653,
    "path" : "~/GenoudBP/R/GA-ANN.R",
    "project_path" : "R/GA-ANN.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}